{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Notes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-07T18:14:26.052676Z",
     "start_time": "2023-09-07T18:14:26.033303Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from typing import List, Tuple\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import lyricsgenius\n",
    "plt.style.use(\"dark_background\")\n",
    "# sns.set_theme(style=\"darkgrid\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-07T16:31:03.447927Z",
     "start_time": "2023-09-07T16:31:03.441713Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_lyrics(text: str):\n",
    "    return \" \".join(text.split(\"\\n\")[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-07T16:25:11.904230Z",
     "start_time": "2023-09-07T16:25:11.891243Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_text_into_languages(text: str) -> Tuple[List[str], List[str]]:\n",
    "    \"\"\"\n",
    "    Splits a mixed-language text into separate lists of English and Korean words.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input mixed-language (Korean and English) text.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[str], List[str]]: A tuple containing two lists of words,\n",
    "        where the first list contains English words and the second list contains Korean words.\n",
    "    \"\"\"\n",
    "    english_words = re.findall(r'\\b[a-zA-Z]+\\b', text)\n",
    "    korean_words = re.findall(r'\\b[가-힣]+\\b', text)\n",
    "    return english_words, korean_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "## Used for collecting lyric data from Genius ##\n",
    "################################################\n",
    "\n",
    "# token = \"\"\n",
    "# genius = lyricsgenius.Genius(token)\n",
    "# genius.remove_section_headers = True # Remove section headers (e.g. [Chorus]) from lyrics when searching\n",
    "# genius.skip_non_songs = True # Include hits thought to be non-songs (e.g. track lists)\n",
    "# genius.excluded_terms = [\"(Remix)\", \"(Live)\", \"(Cover)\"] # Exclude songs with these words in their title\n",
    "\n",
    "# artists = [\n",
    "#     \"NewJeans\",\n",
    "#     \"BTS\",\n",
    "#     \"(G)I-DLE\",\n",
    "#     \"FIFTY FIFTY\",\n",
    "#     \"AESPA\",\n",
    "#     \"BLACKPINK\",\n",
    "#     \"TWICE\",\n",
    "#     \"Enhyphen\",\n",
    "#     \"Stray Kids\",\n",
    "#     \"TOMORROW X TOGETHER\"\n",
    "# ]\n",
    "\n",
    "# data = {}\n",
    "# for artist in artists:\n",
    "#     data[artist] = {}\n",
    "#     songs = genius.search_artist(artist, sort=\"title\").songs\n",
    "#     for song in songs:\n",
    "#         print(f\"Parsing {song} by {artist}\")\n",
    "#         title = song.title\n",
    "#         eng_words, kor_words = split_text_into_languages(\n",
    "#             clean_lyrics(song.lyrics)\n",
    "#         )\n",
    "#         data[artist][title] = {\n",
    "#             \"Total English Words\": len(eng_words),\n",
    "#             \"Total Korean Words\": len(kor_words)\n",
    "#         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-07T18:37:09.415605Z",
     "start_time": "2023-09-07T18:37:09.362452Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict({(i,j): data[i][j] \n",
    "                           for i in data.keys() \n",
    "                           for j in data[i].keys()},\n",
    "                       orient='index').reset_index()\n",
    "df = df.rename(columns={\"level_0\":\"Artist\",\"level_1\":\"Song Name\"})\n",
    "df.to_csv(\"data/language_distribution_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-07T18:37:33.068591Z",
     "start_time": "2023-09-07T18:37:33.051955Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1104 entries, 0 to 1103\n",
      "Data columns (total 4 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   Artist               1104 non-null   object\n",
      " 1   Song Name            1104 non-null   object\n",
      " 2   Total English Words  1104 non-null   int64 \n",
      " 3   Total Korean Words   1104 non-null   int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 34.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-07T18:37:39.210155Z",
     "start_time": "2023-09-07T18:37:39.166098Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total English Words</th>\n",
       "      <th>Total Korean Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1104.000000</td>\n",
       "      <td>1104.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>183.580616</td>\n",
       "      <td>114.571558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>308.235994</td>\n",
       "      <td>107.870857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>78.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>147.000000</td>\n",
       "      <td>116.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>233.000000</td>\n",
       "      <td>192.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5948.000000</td>\n",
       "      <td>792.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Total English Words  Total Korean Words\n",
       "count          1104.000000         1104.000000\n",
       "mean            183.580616          114.571558\n",
       "std             308.235994          107.870857\n",
       "min               0.000000            0.000000\n",
       "25%              78.000000            0.000000\n",
       "50%             147.000000          116.500000\n",
       "75%             233.000000          192.000000\n",
       "max            5948.000000          792.000000"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
